{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"DSAN 5000 HW 4.2: Visualizing Topics with t-SNE\"\n",
    "format:\n",
    "  html:\n",
    "    toc: true\n",
    "    embed-resources: true\n",
    "    df-print: kable\n",
    "    link-external-newwindow: true\n",
    "    link-external-icon: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While in the previous part we looked at how unsupervised learning algorithms can discover meaningful latent properties of **documents** (the section of the NY Times that the article was published in), here we'll see how t-SNE can allow us to discover meaningful latent properties of **words**.\n",
    "\n",
    "Specifically, in this part we will take the **4-dimensional** document distributions we inferred using the `nmf_model` object in HW4.1, as a simple first look at how t-SNE is able to approximate 4-dimensional similarity within a 2-dimensional plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Imports and Global Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Trained NMF model not found. You'll need to complete HW4.1 Step 10 first)\n"
     ]
    }
   ],
   "source": [
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read(\"hw4.ini\")\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# The key scikit-learn class we'll use in this part!\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# For plotting words within the 2-dimensional t-SNE space\n",
    "import plotly.express as px\n",
    "\n",
    "# Loading the nmf_model object we created and trained in HW4.1\n",
    "nmf_model_fpath = config.get('DataPaths', 'nmf_model_fpath')\n",
    "if not os.path.isfile(nmf_model_fpath):\n",
    "    print(\"(Trained NMF model not found. You'll need to complete HW4.1 Step 10 first)\")\n",
    "else:\n",
    "    print(f\"Loading NMF model from {nmf_model_fpath}...\")\n",
    "    with open(\"./data/nmf_model.pkl\", 'rb') as infile:\n",
    "        nmf_model = pickle.load(infile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: The Document-Topic Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following code cell, use the `nmf_model` object loaded above to create a `DataFrame` object named `term_topic_df`, where each row represents a **word** and each column represents the relevance weight of the word for that topic (the first column should contain the word's Topic 0 relevance, the second column should contain the word's Topic 1 relevance, and so on).\n",
    "\n",
    "Since `nmf_model.components_` already contains a matrix where each **row** represents a topic and each **column** represents a word, you should be able to apply a simple transformation to this object to obtain `term_topic_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: hw4-2-2-response\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Fit the t-SNE Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, it's time to use `scikit-learn`'s `TSNE` class, which implements the t-SNE procedure you learned in lecture! In the following code cell:\n",
    "\n",
    "* Create an object called `tsne_topic_model` (you don't need to specify any hyperparameters here, as the default values work fine in this case), and then\n",
    "* Use the `fit_transform()` function to obtain a matrix containing the **2-dimensional** t-SNE-based projections of our original 4-dimensional data, and call this matrix `tsne_topic_projections`.\n",
    "\n",
    "Use `tsne_topic_projections.shape` as the last line in the cell to verify that `tsne_topic_projections` is an $N \\times 2$ matrix, where $N$ is the number of words in the vocabulary you constructed in HW4.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: hw4-2-3-response\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Filter t-SNE Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, at the beginning of the following code cell, convert the `NumPy` matrix `tsne_topic_projections` created in the previous step into a Pandas `DataFrame` object called `tsne_topic_df`, with the first column named `\"x\"` and the second named `\"y\"`. These will form the $x$ and $y$ coordinates for each point in our plot below.\n",
    "\n",
    "Once `tsne_topic_df` has been constructed, load the tf-idf word weights from the filepath given in `hw4.ini` (see HW4.1 Step 5, where you created and saved the word weights in the first place), and append the contents of this word weights file to `tsne_topic_df` as two additional columns (named `\"word\"` and `\"weight\"`).\n",
    "\n",
    "*(As was the case in HW4.1, you should be able to use `pd.concat()` to accomplish this, as long as the order of the words in `word_weights.csv` is the same as the order of the words in `tsne_topic_projections`.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: hw4-2-4-load-weights\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sadly, if we now jumped directly to plotting the points in `tsne_topic_df` (the t-SNE coordinates for **all** ~5K words), our plot would just look like a giant chaotic blob of points. So, here we filter the full contents of the `DataFrame` to only contain the words we found to be **most important** (in terms of tf-idf weights) in HW4.1\n",
    "\n",
    "In the following code cell, on the basis of the global variable `num_words_tsne` defined in `hw4.ini`, filter `tsne_topic_df` so it contains only the projected 2-dimensional t-SNE coordinates for the top $N$ words (by tf-idf weight), where $N$ is the value of `num_words_tsne`.\n",
    "\n",
    "This means that, after running the following code cell, `tsne_topic_df` should be an $N \\times 4$ `DataFrame` object, with the $N$ rows corresponding to the $N$ words with highest tf-idf score (as found in HW4.1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: hw4-2-4-filter\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Plot t-SNE Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have `tsne_topic_df` ready for plotting, the following code cell provides you with code for generating an **interactive** plot of the top $N$ points from the 2-dimensional space estimated in this notebook. As long as the `TSNE` fitting went as expected (and as long as the `\"x\"`, `\"y\"`, and `\"word\"` columns are named correctly), you should be able to hover over the points in the resulting plot to see what word each point in the space represents.\n",
    "\n",
    "In a Markdown cell below the plot, please write one or two sentences describing a pattern you see in terms of clusters in the t-SNE space: do words with similar semantic meaning, for example, seem to be close together? Do you observe clustering among the words, and can you describe one of these clusters? (*Why* are the words in the cluster grouped together? What is the commonality between them in terms of their semantic meaning?)\n",
    "\n",
    "*(Note: You may get a warning message about `nbformat` being required by Plotly for interactive labels. If so, you can install this library using `pip install nbformat` or `conda install nbformat` as needed.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'tsne_topic_df' in globals():\n",
    "    px.scatter(tsne_topic_df, x=\"x\", y=\"y\", hover_name=\"word\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(Your observations here)*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
